\documentclass{beamer}
\usepackage[utf8]{inputenc}

\usetheme{Madrid}
\usecolortheme{default}
\useinnertheme{circles}

\definecolor{Logo1}{rgb}{0.208, 0.2865, 0.373}
\definecolor{Logo2}{rgb}{0.000, 0.674, 0.863}

\setbeamercolor*{palette primary}{bg=Logo1, fg=white}
\setbeamercolor*{palette secondary}{bg=Logo2, fg=white}
\setbeamercolor*{palette tertiary}{bg=white, fg=Logo1}
\setbeamercolor*{palette quaternary}{bg=Logo1,fg=white}
\setbeamercolor{structure}{fg=Logo1} % itemize, enumerate, etc
\setbeamercolor{section in toc}{fg=Logo1} % TOC sections

\usepackage{graphicx,animate}
%------------------------------------------------------------
%This block of code defines the information to appear in the
%Title page
\title[Linear Algebra] %optional
{Column Space \& Nullspace; Solving $Ax=0$ \& $Ax=b$}

\subtitle{Lecture 3}

\author[11910803@mail.sustech.edu.cn] % (optional)
{
    Zhang Ce
}

\institute[] % (optional)
{
    Department of Electrical and Electronic Engineering\\
    Southern University of Science and Technology
}

\date[2021.10.12] % (optional)
{2021.10.12}


%End of title page configuration block
%------------------------------------------------------------



%------------------------------------------------------------
%The next block of commands puts the table of contents at the
%beginning of each section and highlights the current section:

\AtBeginSection[]
{
\begin{frame}
    \frametitle{Table of Contents}
    \tableofcontents[currentsection]
\end{frame}
}
%------------------------------------------------------------


\begin{document}

%The next statement creates the title page.
\frame{\titlepage}


%---------------------------------------------------------
%This block of code is for the table of contents after
%the title page
\begin{frame}
\frametitle{Table of Contents}
\tableofcontents
\end{frame}
%---------------------------------------------------------
\section{A Brief Review of Last Lecture}
\begin{frame}{Last Lecture, We Discuss\dots}
Three parts in last lecture:
    \begin{enumerate}
        \item Row Exchanges and $PA=LU$ Factorization\\
        permutation matrix, process of $PA=LU$ factorization
        \item Inverse of Matrix\\
        existence of inverse, calculation of inverse, block inverse
        \item Vector Spaces and Subspaces\\
        definition of vector spaces and subspaces
    \end{enumerate}

Don't forget row method and column method for matrix multiplication. Things will get easier if you know these methods!
\end{frame}

\begin{frame}{Matrix Multiplication}
\begin{examples}
Compute the matrix multiplication.
    \begin{equation*}
        \left[ \begin{matrix}
            3&		-1&       1\\
            1&		 0&       1\\
            0&		 1&       2\\
        \end{matrix} \right] \left[ \begin{matrix}
            1&		 0&       1\\
            1&		-1&      -1\\
            1&		 2&       1\\
        \end{matrix} \right] =\left[ \begin{matrix}
            3&		 3&       5\\
            2&		 2&       2\\
            3&		 3&       1\\
        \end{matrix} \right]
    \end{equation*}
\end{examples}

\begin{enumerate}
    \item The regular (row-col) way. (Row of A) multiply (Column of B).
    \item The row way. Linear combination of (Row of B).
    \item The column way. Linear combination of (Column of A).
    \item The col-row way. (Column of A) multiply (Row of B).
\end{enumerate}

There is also an additional method: block method.
\end{frame}

\begin{frame}{Why $P^T=P^{-1}$?}
Why $P^T=P^{-1}$? A direct explanation:
\vspace{3pt}

\begin{columns}
\column{0.5\textwidth}
\begin{equation*}
    P=\left[ \begin{matrix}
        0&		1&		0&		0\\
        0&		0&		1&		0\\
        0&		0&		0&		1\\
        1&		0&		0&		0\\
    \end{matrix} \right]
\end{equation*}

\begin{itemize}
    \item 1 at $(1,2)$: (Row 2) $\rightarrow$ (Row 1).
    \item 1 at $(2,3)$: (Row 3) $\rightarrow$ (Row 2).
    \item 1 at $(3,4)$: (Row 4) $\rightarrow$ (Row 3).
    \item 1 at $(4,1)$: (Row 1) $\rightarrow$ (Row 4).
\end{itemize}

\column{0.5\textwidth}
\begin{equation*}
    P^T=\left[ \begin{matrix}
        0&		0&		0&		1\\
        1&		0&		0&		0\\
        0&		1&		0&		0\\
        0&		0&		1&		0\\
    \end{matrix} \right]
\end{equation*}

\begin{itemize}
    \item 1 at $(2,1)$: (Row 1) $\rightarrow$ (Row 2).
    \item 1 at $(3,2)$: (Row 2) $\rightarrow$ (Row 3).
    \item 1 at $(4,3)$: (Row 3) $\rightarrow$ (Row 4).
    \item 1 at $(1,4)$: (Row 4) $\rightarrow$ (Row 1).
\end{itemize}
\end{columns}

\vspace{7pt}
Exchange A and B then exchange B and A will result in exchange nothing.

\end{frame}

\begin{frame}{Existence of Inverse}
According to definition, if it has an inverse, there exist a matrix $B$ to let $AB=I$, thus, $B$ is the inverse of $A$.
\begin{equation*}
    \left[ \begin{matrix}
        1&		2\\
        3&		6\\
    \end{matrix} \right] \left[ \begin{matrix}
        x&		\cdot\\
        y&		\cdot\\
    \end{matrix} \right] =\left[ \begin{matrix}
        1&		0\\
        0&		1\\
    \end{matrix} \right]
\end{equation*}

Recall the column method of matrix multiplication:
\begin{equation*}
    x\left[ \begin{array}{c}
        1\\
        3\\
    \end{array} \right] +y\left[ \begin{array}{c}
        2\\
        6\\
    \end{array} \right] =\left[ \begin{array}{c}
        1\\
        0\\
    \end{array} \right]
\end{equation*}

It may lead you to think about column picture.

\vspace{3pt}
Is it possible? Linear combinations of the 2 column vectors are still on the straight line!

\vspace{3pt}
Therefore, the inverse cannot exist for this matrix $A$.
\end{frame}



\begin{frame}{Calculation of Inverse}
Another important problem: how to find the inverse $A^{-1}$ for invertible matrix $A$?

\vspace{3pt}
Gauss-Jordan method, right? But how does it come?

\vspace{3pt}
You may think up with this method:
\begin{equation*}
    \left[ \begin{matrix}
        1&		2\\
        3&		7\\
    \end{matrix} \right] \left[ \begin{matrix}
        a&		c\\
        b&		d\\
    \end{matrix} \right] =\left[ \begin{matrix}
        1&		0\\
        0&		1\\
    \end{matrix} \right]
\end{equation*}

To find the inverse, we only need to find the 4 unknowns $a,b,c,d$.

\vspace{3pt}
Use the column method of matrix multiplication to think, actually we only need to find the solutions for the following 2 linear equation systems:

\vspace{6pt}
\begin{columns}
    \column{0.5\textwidth}
    \begin{equation*}
        \left[ \begin{matrix}
            1&		2\\
            3&		7\\
        \end{matrix} \right] \left[ \begin{array}{c}
            a\\
            b\\
        \end{array} \right] =\left[ \begin{array}{c}
            1\\
            0\\
        \end{array} \right]
    \end{equation*}

    \column{0.5\textwidth}
    \begin{equation*}
        \left[ \begin{matrix}
            1&		2\\
            3&		7\\
        \end{matrix} \right] \left[ \begin{array}{c}
            c\\
            d\\
        \end{array} \right] =\left[ \begin{array}{c}
            0\\
            1\\
        \end{array} \right]
    \end{equation*}
\end{columns}

\vspace{6pt}
Then, the problem returns to Gauss elimination!
\end{frame}

\begin{frame}{Calculation of Inverse}
Let's solve one of the systems together.
\begin{equation*}
    \left[ \begin{matrix}
        1&		2\\
        3&		7\\
    \end{matrix} \right] \left[ \begin{array}{c}
        a\\
        b\\
    \end{array} \right] =\left[ \begin{array}{c}
        1\\
        0\\
    \end{array} \right]
\end{equation*}

Augmented matrix:
\begin{equation*}
    \left[ \begin{matrix}
        1&		2&		1\\
        3&		7&		0\\
    \end{matrix} \right]
\end{equation*}

Solve this equation system by Gauss elimination:
\begin{equation*}
    \left[ \begin{matrix}
        1&		2&		1\\
        3&		7&		0\\
    \end{matrix} \right] \rightarrow \left[ \begin{matrix}
        1&		2&		1\\
        0&		1&		-3\\
    \end{matrix} \right] \rightarrow \left[ \begin{matrix}
        1&		0&		\mathbf{7}\\
        0&		1&		\mathbf{-3}\\
    \end{matrix} \right]
\end{equation*}

The solution is $\left[ \begin{array}{c}
	a\\
	b\\
\end{array} \right] =\left[ \begin{array}{c}
	7\\
	-3\\
\end{array} \right] $ as the last column displays.

\vspace{3pt}
Then we calculate another equation system\dots


\end{frame}

\begin{frame}{Calculation of Inverse}
At this time, Jordan appears, he said to Gauss: "Why not solve 2 equations at once?"

\vspace{3pt}
The total augmented matrix is:
\begin{equation*}
    \left[ \begin{matrix}
        1&		2&		1&		0\\
        3&		7&		0&		1\\
    \end{matrix} \right]
\end{equation*}

Then, if we eliminate the coefficient to $I$, the solution of 2 equation systems (inverse of $A$) will appear in the last 2 columns!

\begin{equation*}
    \left[ \begin{matrix}
        1&		2&		1&		0\\
        3&		7&		0&		1\\
    \end{matrix} \right] \rightarrow \left[ \begin{matrix}
        1&		2&		1&		0\\
        0&		1&		-3&		1\\
    \end{matrix} \right] \rightarrow \left[ \begin{matrix}
        1&		0&		7&		-2\\
        0&		1&		-3&		1\\
    \end{matrix} \right]
\end{equation*}

So, we can finally get that
\begin{equation*}
    A^{-1}=\left[ \begin{matrix}
        7&		-2\\
        -3&		1\\
    \end{matrix} \right]
\end{equation*}

That is the Gauss-Jordan method, and I believe you can have a better understanding on it now.
\end{frame}

\begin{frame}{Additional: Block Method to Find the Inverse}
\begin{example}
    Find the inverse of this matrix, given that $A,B,C$ are all invertible matrices. Please express the result in matrix form.
    \begin{equation*}
        L=\left[ \begin{matrix}
            A&		0\\
            B&		C\\
        \end{matrix} \right],\:
        M=\left[ \begin{matrix}
            0&		A\\
            B&		0\\
        \end{matrix} \right]
    \end{equation*}
\end{example}

\textbf{Solution:}

Core idea: Treat all block matrices as a single entry.
\begin{equation*}
    \left[ \begin{matrix}
        A&		0&		I&		0\\
        B&		C&		0&		I\\
    \end{matrix} \right] \rightarrow \left[ \begin{matrix}
        A&		0&		I&		0\\
        0&		C&		-BA^{-1}&		I\\
    \end{matrix} \right] \rightarrow \left[ \begin{matrix}
        I&		0&		A^{-1}&		0\\
        0&		I&		-C^{-1}BA^{-1}&		C^{-1}\\
    \end{matrix} \right]
\end{equation*}

\begin{equation*}
    L^{-1}=\left[ \begin{matrix}
        A^{-1}&		0\\
        -C^{-1}BA^{-1}&		C^{-1}\\
    \end{matrix} \right]
\end{equation*}

\end{frame}

\section{Vector Spaces and Subspaces}
\begin{frame}{Vector Spaces}
Once the vector in a space can have addition and scalar multiplication, and the result is still in this space, then the space can be called vector spaces.

Some standard vector spaces:
\begin{itemize}
    \item $\mathbb{R}^1$: x axis. 1 dimensional.
    \item $\mathbb{R}^2$: x-y plane. 2 dimensional.
    \item $\mathbb{R}^3$: x-y-z space. 3 dimensional.
\end{itemize}

\begin{example}
    Are these sets below vector spaces? Explain it.
    \begin{enumerate}
        \item $\mathbb{R}^3$ space without the origin.
        \item $\mathbb{R}^2$ plane without the third quadrant.
        \item $\mathbb{R}^{2021}$ space.
        \item $\mathbb{C}^2$ space.
    \end{enumerate}
\end{example}
\end{frame}

\begin{frame}{Subspaces}
\begin{definition}
    If $S$ in a nonempty subset of a vector space $V$, and $S$ satisfies the conditions: linear combinations stay in the subspace.
    \begin{itemize}
        \item $c\mathbf{u}\in S$ whenever $\mathbf{u}\in S$ for any scalar c
        \item $\mathbf{u} + \mathbf{v}\in S$ whenever $\mathbf{u}\in S$ and $\mathbf{v}\in S$
    \end{itemize}
    Then $S$ is said to be a subspace of $V$.
\end{definition}

To say it in human language, if a space $S$ is a closed under linear combinations and it is in a vector space $V$, then $S$ is a subspace of $V$.

\vspace{3pt}
Remember that the origin should exist in every subspace or vector space!

\vspace{3pt}
It is an abstract concept but no need to worry about that. You will understand it later.
\end{frame}
\end{document}